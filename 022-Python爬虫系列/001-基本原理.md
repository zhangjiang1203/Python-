## 爬虫基本原理

>1.爬虫通常就是从某个网站开始爬取这个页面的数据，
找到这个页面的其他链接，然后从这个链接开始继续爬取数据，这样一直不停的爬下去，批量的获取数据。
爬虫就是一个一直不停爬取网页获取数据的程序。

### 爬虫的基本流程

> 1.发起请求
>> 向指定的目标站点发送请求，可以包含额外的请求信息，发送一个```request```
>
> 2.获取请求相应内容
>> 服务器响应之后，我们得到一个```response```，这就是我们得到的数据
>
> 3.解析内容
>> 得到的内容可能为```html```，```json```，```xml```等数据类型，可以使用正则表达式，网页解析库等进行解析，
把服务器的数据解析到本地，进行解析在展示出来
>
> 4.保存数据
>> 数据根据返回的数据格式进行保存，文本数据通常保存在数据库中，


### 什么是```Request```？
>1.浏览器发送信息给该网址所在的服务器，这个过程叫做```http request````
>
>2.request包含信息
>* 请求方式：请求方式主要有```get```、```post```、```header```、```put```、```delete```等请求方式，这几种请求方式的区别可自行百度，
>* 请求```URL```，URL全称是统一资源定位符
>* 请求头(```request header```):请求头包含请求的头部信息，比如 ```User-Agent```
，```Host```，```Cookies```等信息
>* 请求体：请求体是请求额外携带的请求信息，如 登录的时候提交的用户名和密码   


### 什么是```Response```

>1.服务器收到浏览器发送的请求之后，根据请求的信息作出对应的处理，返回对应的信息，这个过程叫做```Http Response```
>
>2.```response```中包含的信息
>* 响应状态：服务器响应的状态，比如 200代表成功，301跳转界面 404表示找不到界面，502表示服务器错误
>* 响应头(```Request Headers```):比如内容类型，内容长度，服务器信息，设置```cookies```等信息
>* 响应体：响应体是最主要的部分，包含请求的资源内容，


### model演示

```python
import requests

headers = {'User-Agent':'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36'}
resp = requests.get('http://www.baidu.com/img/baidu_jgylogo3.gif',headers=headers)
print(resp.content) # 二进制文件使用content
# 保存图片
with open('logo.gif','wb') as f:
    f.write(resp.content)
    print('Ok')
```

### 爬虫信息解析方式

* 直接处理，比如简单的页面文档，只要去除一些空格的数据；
* Json解析，处理Ajax加载的页面；
* 正则表达式；
* BeautifulSoup库；
* PyQuery；
* XPath。



